{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b750b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "from collections import Counter\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5e5bdd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_texts(local_pride: str = \"./data/pride.txt\",\n",
    "               local_sense: str = \"./data/sense.txt\"):\n",
    "    \"\"\"Load 'Pride and Prejudice' and 'Sense and Sensibility' from disk.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    local_pride : str\n",
    "        Path to Pride and Prejudice text file. Defaults to './data/pride.txt'.\n",
    "    local_sense : str\n",
    "        Path to Sense and Sensibility text file. Defaults to './data/sense.txt'.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple[str, str]\n",
    "        (pride_text, sense_text).\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    FileNotFoundError\n",
    "        If either file is missing.\n",
    "    \"\"\"\n",
    "    p1, p2 = Path(local_pride), Path(local_sense)\n",
    "\n",
    "    if not p1.exists():\n",
    "        raise FileNotFoundError(\n",
    "            f\"Missing file: {p1}\\n\"\n",
    "            \"→ Please place 'pride.txt' at this path or pass the correct path to load_texts(...).\"\n",
    "        )\n",
    "    if not p2.exists():\n",
    "        raise FileNotFoundError(\n",
    "            f\"Missing file: {p2}\\n\"\n",
    "            \"→ Please place 'sense.txt' at this path or pass the correct path to load_texts(...).\"\n",
    "        )\n",
    "\n",
    "    pride = p1.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "    sense = p2.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "    return pride, sense\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "055ed3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(text: str) -> str:\n",
    "    \"\"\"Normalize a Gutenberg-like text for tokenization.\n",
    "\n",
    "    Steps\n",
    "    -----\n",
    "    1) Strip Project Gutenberg header/footer if present\n",
    "       (*** START ... *** to *** END ... ***).\n",
    "    2) Normalize newlines to '\\\\n'.\n",
    "    \"\"\"\n",
    "    if not text:\n",
    "        return \"\"\n",
    "\n",
    "    # Try to clip strictly between the START and END markers if both exist\n",
    "    start_match = re.search(r\"\\*\\*\\*\\s*START OF (?:THIS|THE) PROJECT GUTENBERG EBOOK.*?\\*\\*\\*\", text, flags=re.IGNORECASE|re.DOTALL)\n",
    "    end_match   = re.search(r\"\\*\\*\\*\\s*END OF (?:THIS|THE) PROJECT GUTENBERG EBOOK.*?\\*\\*\\*\", text,   flags=re.IGNORECASE|re.DOTALL)\n",
    "    if start_match and end_match and end_match.start() > start_match.end():\n",
    "        text = text[start_match.end():end_match.start()]\n",
    "\n",
    "    # Normalize Windows line endings\n",
    "    return text.replace(\"\\r\\n\", \"\\n\").strip()\n",
    "\n",
    "\n",
    "# -------- Tokenization helpers (simple) --------\n",
    "\n",
    "WORD_RE = re.compile(r\"[A-Za-z']+\")  # keep apostrophes in words (e.g., don't)\n",
    "\n",
    "def words(text: str):\n",
    "    \"\"\"Simple word tokenizer (lowercased, ASCII letters + apostrophes).\"\"\"\n",
    "    return WORD_RE.findall(text.lower())\n",
    "\n",
    "\n",
    "def sentences(text: str):\n",
    "    \"\"\"Naive sentence splitter using punctuation boundaries.\"\"\"\n",
    "    return [s.strip() for s in re.split(r\"(?<=[.!?])\\s+\", text) if s.strip()]\n",
    "\n",
    "\n",
    "# -------- Frequency & keyness utilities --------\n",
    "\n",
    "def top_words(word_list, min_len=4, extra_stop=None, n=30):\n",
    "    \"\"\"Return top-N frequent words after lightweight filtering.\"\"\"\n",
    "    base_stop = {\n",
    "        \"the\",\"and\",\"to\",\"of\",\"a\",\"i\",\"it\",\"in\",\"that\",\"was\",\"he\",\"you\",\"is\",\"for\",\"on\",\"as\",\n",
    "        \"with\",\"his\",\"her\",\"at\",\"be\",\"she\",\"had\",\"not\",\"but\",\"said\",\"they\",\"them\",\"this\",\"so\",\"all\",\"one\",\"very\",\n",
    "        \"there\",\"what\",\"were\",\"from\",\"have\",\"would\",\"could\",\"when\",\"been\",\"their\",\"we\",\"my\",\"me\",\"or\",\"by\",\"up\",\"no\",\"out\",\"if\",\n",
    "        # name stopwords (tweak as you like)\n",
    "        \"elizabeth\",\"darcy\",\"bennet\",\"jane\",\"willoughby\",\"marianne\",\"dashwood\"\n",
    "    }\n",
    "    if extra_stop:\n",
    "        base_stop |= set(extra_stop)\n",
    "\n",
    "    c = Counter(w for w in word_list if len(w) >= min_len and w not in base_stop)\n",
    "    return c.most_common(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6927480a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pride chars: 728,713 | Sense chars: 670,674\n"
     ]
    }
   ],
   "source": [
    "# ---- Load & report ----\n",
    "pride_raw, sense_raw = load_texts()\n",
    "pride = normalize(pride_raw)\n",
    "sense = normalize(sense_raw)\n",
    "\n",
    "print(f\"Pride chars: {len(pride):,} | Sense chars: {len(sense):,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c93e19f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pride words: 128,565 | Sense words: 120,869\n",
      "Pride sentences: 5,942 | Sense sentences: 4,663\n"
     ]
    }
   ],
   "source": [
    "# Tokenize into word lists\n",
    "pride_words = words(pride)\n",
    "sense_words = words(sense)\n",
    "\n",
    "# Split into sentence lists\n",
    "pride_sentences = sentences(pride)\n",
    "sense_sentences = sentences(sense)\n",
    "\n",
    "# Report counts\n",
    "print(f\"Pride words: {len(pride_words):,} | Sense words: {len(sense_words):,}\")\n",
    "print(f\"Pride sentences: {len(pride_sentences):,} | Sense sentences: {len(sense_sentences):,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a4f916a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Pride: [('which', 568), ('your', 455), ('will', 428), ('such', 397), ('much', 337), ('more', 337), ('miss', 315), ('must', 315), ('bingley', 310), ('than', 300), ('should', 258), ('know', 244), ('though', 238), ('herself', 236), ('well', 230)]\n",
      "Top Sense: [('elinor', 685), ('which', 593), ('more', 408), ('your', 386), ('every', 376), ('will', 363), ('than', 362), ('such', 359), ('much', 290), ('only', 287), ('must', 283), ('sister', 282), ('edward', 263), ('mother', 259), ('herself', 255)]\n"
     ]
    }
   ],
   "source": [
    "# Show top stylistic vocabulary (first 15 entries)\n",
    "print(\"Top Pride:\", top_words(pride_words)[:15])\n",
    "print(\"Top Sense:\", top_words(sense_words)[:15])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
